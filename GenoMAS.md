[导言]

在科学研究越来越依靠标准化精密计算手段的今天，用智能体技术来自动化加速科研的潜力让人心潮澎湃。可今天人们使用Cursor, Codex之类的智能体进行科研或执行重要任务时，仍然主要拿它们作为辅助工具，每运行几步就需要等待人验证或提出修改意见。那么如果我们完全交由智能体自动化，如何让它足够可信地代替人完成一部分需要精密思考的科研工作呢？

这是一个宏大而开放的问题。我们近期完成的，倾注一年半心血的科研项目，就在一个具体的科学场景中，初步探索答案。我们着眼于通过基因表达分析这个任务，并通过它来挖掘在控制各种混淆因子影响后仍然稳定的基因-表型关联。具体来说，从原始的转录组数据和半结构化的临床信息出发，自动完成数据选择、预处理与统计分析，识别与目标性状显著相关的基因集合，并支持条件分析以剔除年龄、性别、共病等变量的干扰。之所以选择它，一方面因为基因-表型关联对于疾病易感、药物反应与患者预后等问题至关重要；另一方面它足够难：平台异构、命名演化、批次效应、样本量与维度的不匹配，以及隐匿的混淆因素，使这一任务既代表了生物医学数据分析的普遍挑战，也对智能体技术的规划、代码生成与错误恢复能力提出了实打实的要求。

[为什么自动化转录组分析这么难]

在开始接到这个课题的很长一段时间里，我们是一筹莫展的。考虑混淆后的基因-表型关联绝大部分是未知的，无法在现有文献中验证。在研发这样的智能体之前，为了评估它的性能好坏，我们需要有一套标准。于是想到，如果有一个数据集收集了人类专家按照最佳实践分析数据得到的高质量结果，与之对比就能判断自动化方法的优劣。我们首先找到CMU的一位计算生物学教授，邀请她加入这个课题，希望能组织她教授的一门研究生课上的学生来共同打造这个基准数据集。在一次视频会议里，我向她展示了这个任务需要的分析流程后，她摇了摇头，说这个太专业化了（specialized），作为课程项目来说对学生的挑战太大。我们只好在校内组织一个团队来建造这个数据集。我们很快就发现那个教授说得没错，我们发现甚至网上的样例代码都不容易搜到，找到的寥寥几个有用的例子都是基于R的。于是我们这些CS背景的人通过看书、看网课，请教生物专家，恶补这方面的知识，一边召集团队，等了很久才在本校凑齐一个有足够计算生物背景的队伍，来建这个数据集。

基准数据集建好之后，就是智能体的研发。我们先试了当时最强的大模型和最先进的智能体。那会还是GPT-4时代，不出所料，所有方法和模型都无法生成代码来跑通从原始数据到分析结果的全流程，更不用说准确率了。现在的情况好了很多，随着大模型能力的飙升，我们发现从Claude 4开始，代码跑通已经不成问题了。但我们测试现有的先进智能体时，发现他们仍然经常犯隐蔽而严重的错误，而使得整个分析得到的结果科学上无效 (在论文附录A有详细的分析和例子)。

自动化方法在这里遇到的困难，植根于大模型自身的特点。首先，作为统计模型，它完成任务的表现高度依赖于任务相关互联网数据的高频性。它在众多学科展现出的强大能力，也源于互联网上大量的教材、习题等语料。除了解数学题、算法题等相对容易靠强化学习后训练提升的领域以外，真实世界大部分专业性和开放性强的任务中，大模型都会面临分布外泛化的严峻挑战。如果任务足够专业化，就像一个new grad到了公司里需要从头接收培训才能上手的任务，大模型往往也难以正确完成。其次，大模型是把所有信息以字符串的形式一股脑输入attention处理，这难以应对需要从若干个几十至几百兆的文件中整合数据、分析判断的基因表达分析任务。当上下文窗口过长，往往会淹没重要信息，严重降低大模型的任务表现。人的“工作记忆”远不如大模型的上下文窗口，但人会主动探索，会使用工具，也会选择对哪些输入信息进行思维深加工。一个熟练的生信专家只需要在流程的几个节点从大型文件里阅读关键的几十行，就能高质量完成整个分析任务。

[设计理念：可信的科学自动化，需要结合智能体和工作流的优势]

有了上面的思考，我们的目标就很明晰了：在智能体层面弥补大模型的不足，一是给它足够的领域知识帮它完成“入行培训”，规范它行为的同时，让它可以在此基础上，在任务中自己积累经验；二是在规划模块的层面上让它自主探索环境，选择性地处理和整合数据。探索就不可避免会犯错，所以我们要让它能即时从错误中恢复，不随着上下文积累变长后加剧的”自我条件”效应走入死胡同。我们在设计智能体的过程中，阶段性地拿我们的基准数据集评估性能，不断迭代，力求研发一个可信的全自动化基因表达分析任务的智能体。

这就引发一个问题，什么是可信的科学自动化？也许很多人认为，现在的大模型已经足够强大和智慧了，潜力无限。我们只要进一步提升它的agentic能力，再让它学会使用外部工具，那么不久后将来的某一天，它就能可信地自动进行科研工作。虽然这些是非常重要且激动人心的技术路线，可我们认为，即使大模型可以变得非常强大智慧，也不一定“可信”，这是因为，对于科学或者说科研，大家并没有一致认同的标准答案。一个学科里会有观点相左的不同学派，不同实验室对于科研的理解和规则也会有差异。在执行重要任务时，这些差异会体现在操作细则的各个方面，而且越是重要任务，越缺少妥协的余地。倘若向全世界最强的智能体丢一句简单的命令，让它根据自己的想法全自动做科研，再把结果端给用户，恐怕绝大部分用户是不会乐意的--如果ta是个严肃的科研工作者的话。

所以我们认为，可信的科学自动化，首先要让用户选择自己信任的guidelines。这个guidelines也许只是一个具体任务的简单指示，也许是复杂得多的一组文件。对于要进行的任务来说，这个guidelines要包含足够的文本信息让用户确信自己认同它将在这个任务中体现的科研风格、学派立场等等，于是作者选择相信，并对产生的结果愿赌服输。而agent这一侧，则需要确保按照用户信任的guidelines工作，同时也要对实际执行中的各种问题自主地探索解决方案，灵活处理，避免像人为编排的工作流那样僵化。因此，一个可信的智能体是需要结合agent和workflow优势的。

当然，以上只是概念上的思考。由于大模型的概率本质，我们无法确保智能体100%的遵守guidelines，而是通过智能体的编排，在大模型指令遵守和减少幻觉方面进展的基础上再进一步。

[方法设计：把可控的指南与自治的智能体放到一起]

围绕“可信”这一目标，我们把 GenoMAS 设计成一个多角色协作的系统，但始终坚持两个原则：一是让用户选择并提供自己信任的指南（guidelines），把工作方式、学派立场与风险偏好提前固定下来；二是让智能体在该框架内保留足够的自治，针对真实数据的边界情况进行探索、回退与修正。为此，我们把指南组织成可编辑的 DAG，并进一步切分为语义自洽、可原子执行的 Action Unit。编程类智能体在每一步都会基于上下文做出“前进/修订/跳过/回退”的选择：当早期决策导致下游异常时，可以回滚代码与状态到合适的分叉点，沿替代路径继续推进。

系统由六个角色协作完成端到端流程：PI 负责统筹与调度；两位数据工程师分别面向 GEO 与 TCGA 的数据预处理；统计学家承担回归建模与显著基因识别；代码审阅者与领域专家提供质量控制与生物学判断。角色之间通过“带类型的消息协议”通信，形成清晰的请求—响应闭环，避免跨步与遗漏。在代码层面，我们采用“编写—审阅—修订”的多轮循环：审阅者在隔离上下文的前提下检查可执行性与对指南的遵守，必要时给出精确的拒绝与修改建议；编程智能体据此整合历史诊断信息进行修订，直到通过或达到上限。涉及生物学语义的决策（如特征抽取与基因符号映射），由领域专家在聚焦上下文中给出建议，并直接以可执行的形式落地。

为了应对真实数据规模与异质性，我们在工程上加入并行与断点续跑、缓存与资源监控、超时保护等机制；通过“代码记忆”，系统把已通过审阅的片段按 Action Unit 类型索引与重用，从而在保持稳健的前提下逐步积累经验，减少无谓重复。为了保证可复现性与一致性，我们将基因同义词库与基因-表型关联资源本地化、版本化管理。值得一提的是，我们选择“异质模型”的团队配置：擅长代码代理的模型承担编程主力，更强的推理模型主导规划与审阅，而在生物知识上表现突出的模型提供领域判断；这种认知多样性在复杂任务上通常更稳健。

[实验与结果：在 GenoTEX 上的系统检验]

我们在 GenoTEX 基准上系统评估 GenoMAS。该基准覆盖 913 个真实数据集、132 个表型、共 1,384 个基因-表型问题，按照“数据选择—数据预处理—统计分析”三段式进行度量。在数据预处理阶段，我们采用属性交并系数（AJ）、样本交并系数（SJ）与复合相似相关（CSC=AJ×SJ×相关系数均值）来衡量结构与数值的一致性；在统计分析阶段，采用 AUROC、Precision/Recall/F1 与 GSEA 等指标，额外记录端到端执行成功率、时间与成本。

在该基准上，GenoMAS 在数据预处理取得 89.13% 的 CSC，在显著基因识别上取得 60.48% 的 F1，相比此前最优方法分别提升 10.61% 与 16.85%；端到端执行成功率为 98.78%，同时将 API 成本降低了约 44.7%。在同构（单一模型）与异构（多模型协作）的对照中，异构配置带来了额外收益：在保持可控性的同时进一步提升了识别能力，并显著降低了成本。我们也观察到，强通用工具集成的生物医学智能体在这一任务上并不占优，原因并不在于“模型不够强”，而在于设计侧重点不同：本任务更需要在“遵循可复核指南”的前提下处理复杂依赖与边界情形，而不是面向开放域的完全自治。

[进一步分析：瓶颈、消融与系统行为]

把流程拆开看，数据集筛选的难度相对较低，但早期偏差会层层放大。数据预处理呈现典型分化：在表达矩阵处理上，系统取得了稳定的高一致性；而在临床特征抽取上，受制于半结构化文本、命名异构与来源不一致，CSC 明显偏低，是当前主要瓶颈。在统计分析环节，我们用专家预处理数据做了对照：当批次效应校正与协变量控制具备时，F1 可达到约 95% 水平；去掉批次效应校正会显著下降。这一对比表明，困难不在于使用何种回归模型，而在于能否可靠地处理混淆。

在消融实验中，去掉情境感知的引导式规划、领域专家或多轮审阅，都会带来明显退化；把审阅轮数限制为 1 轮进一步说明“看似笨重”的迭代在长链路里确有必要。我们还设置了“零样本、不读数据”的对照，AUROC 仅在 0.56 左右，强调了结构化数据处理与领域推理的不可替代性。从系统行为看，代码记忆在前期很快达到约 65% 的复用率，累计节省了可观的时间；消息流量集中在规划与校验上，PI 低频调度、编程与顾问高频互动的模式与真实跨学科团队相似。

[收束与展望]

回到最初的问题：如何让一个完全自动化的系统在真实科研任务上“值得信任”。GenoMAS 的答案并不依赖某个单一的“更大”或“更强”，而是把可复核的指南、自治的执行与严格的审阅组织在一起，并在真实数据的异质性与边界条件中持续锤炼。它不是终点：临床特征抽取的稳健性、极端数据情形的处理、对指南的进一步可验证遵循，都还有改进空间。我们也在探索把这一范式推广到更复杂的多组学与多模态场景，结合更强的规划算法与更细粒度的执行追踪，加强对因果与混淆的刻画。

如果这篇报道有意义，可能在于它展示了一条务实的路径：先把“如何做事”说清楚，再让系统在这个框架内独立工作、犯错与修正，并用数据说话。我们希望继续把这条路径走实，欢迎同行审视与讨论。
