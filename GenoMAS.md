# GenoMAS：多智能体，让基因表达分析更可信

- 论文标题：GenoMAS: A Multi-Agent Framework for Scientific Discovery via Code-Driven Gene Expression Analysis
- arXiv 链接：https://arxiv.org/abs/2507.21035

## 导言

在科学研究越来越依靠标准化精密计算手段的今天，用智能体技术来自动化加速科研的潜力让人心潮澎湃。但在现实使用中，无论是Cursor还是Codex，这类智能体多作为辅助工具存在：每推进几步，仍需人工介入验证或调整。那么，一旦把流程完全交由智能体自动化，怎样确保它足够可信，能独立完成需要精密判断的科研工作？

这是一个宏大而开放的问题。我们近期完成的，倾注一年半心血的科研项目，就是从一个具体的科学场景切入，初步探索答案。我们着眼于基因表达分析这个任务，并通过它挖掘在控制多种混淆因子后仍然稳定的基因—表型关联。具体来说，从原始的转录组数据和半结构化的临床信息出发，自动完成数据选择、预处理与统计分析，识别与目标性状显著相关的基因集合，并支持条件分析以剔除年龄、性别、共病等变量的干扰。

之所以选择它，一方面因为基因-表型关联对于疾病易感、药物反应与患者预后等问题至关重要；另一方面因为它足够难：平台异构、命名演化、批次效应、样本量与维度的不匹配，以及隐匿的混淆因素，使这一任务既代表了生物医学数据分析的普遍挑战，也对智能体技术的规划、代码生成与错误恢复能力提出了实打实的要求。

本文将分三部分展开：任务难在哪里、我们的方法设计、核心实验结果与观察。

![GenoMAS 多智能体系统示意图](GenoMAS_figs/System_diagram.png)

- 图1（系统架构示意）：GenoMAS 的多智能体协作框架。各角色通过带类型的消息协议进行协作，形成端到端的有序闭环。

## 为什么自动化转录组分析这么难

在开始接到这个课题的很长一段时间里，我们是一筹莫展的。考虑混淆后的基因-表型关联绝大部分是未知的，无法在现有文献中验证。在研发这样的智能体之前，为了评估它的性能好坏，我们需要有一套标准。于是想到，如果有一个数据集收集了人类专家按照最佳实践分析数据得到的高质量结果，与之对比就能判断自动化方法的优劣。我们首先找到CMU的一位计算生物学教授，邀请她加入这个课题，希望能组织她教授的一门研究生课上的学生来共同打造这个基准数据集。在一次视频会议里，我展示了这个任务需要的分析流程后，她摇了摇头，说这个太专业化了（specialized），作为课程项目来说对学生的挑战过大。我们只好在校内组织一个团队来建造这个数据集。我们很快就发现那个教授说得没错，我们发现甚至网上的样例代码都不容易搜到，找到的寥寥几个有用的例子都是基于R的。于是我们这些CS背景的人通过看书、看网课，请教生物专家，恶补这方面的知识，一边召集团队，等了很久才在本校凑齐一个有足够计算生物背景的队伍，来建这个数据集。

基准数据集搭建完成后，我们开始研发智能体。我们先试了当时最强的大模型和最先进的智能体。那会还是GPT-4时代，不出所料，所有方法和模型都无法生成代码来跑通从原始数据到分析结果的全流程，更不用说准确率了。随着大模型能力的飞速提升，从Claude Sonnet 4开始，代码跑通已经不成问题了。可是，当我们测试现有的先进智能体时，发现它们仍然经常犯隐蔽而严重的错误，导致整个分析得到的结果科学上无效（论文附录A有详细的分析和例子）。

自动化方法在这里遇到的困难，植根于大模型自身的特点。首先，作为统计模型，它完成任务的表现高度依赖于任务相关互联网数据的高频性。它在众多学科展现出的强大能力，也源于互联网上大量的教材、习题等语料。除了解数学题、算法题等相对容易靠强化学习后训练提升的领域以外，真实世界大部分专业性和开放性强的任务中，大模型都会面临分布外泛化的严峻挑战。如果任务足够专业化，就像一个优秀的应届毕业生到了公司里需要从头接受培训才能上手的任务，大模型往往也难以正确完成。其次，大模型把所有信息以字符串的形式一股脑输入attention处理，这难以应对需要从若干个几十至几百兆的文件中整合数据、分析判断的基因表达分析任务。当上下文窗口过长，往往会淹没重要信息，严重降低大模型的任务表现。人的“工作记忆”远不如大模型的上下文窗口，但人会主动探索，会使用工具，也会选择对哪些输入信息进行思维深加工。一位熟练的生信专家往往只需在关键节点从大型文件中定位并阅读几十行关键信息，就能高质量完成整个分析任务。

## 设计理念：可信的科学自动化，需要结合智能体和工作流的优势

有了上面的思考，我们的目标就很明晰了：在智能体层面弥补大模型的不足，一是给它足够的领域知识帮它完成“入行培训”，规范它行为的同时，让它可以在此基础上，在任务中自己积累经验；二是在规划模块的层面上让它自主探索环境，选择性地处理和整合数据。探索就不可避免会犯错，所以我们要让它能即时从错误中恢复，避免随着上下文积累变长后加剧的”自我条件”效应走入死胡同。我们在设计智能体的过程中，阶段性地拿我们的基准数据集评估性能，不断迭代，力求研发一个可信的全自动化基因表达分析任务的智能体。

这就引发一个问题：什么是可信的科学自动化？也许很多人认为，现在的大模型已经足够强大和智慧，潜力无限。我们只要进一步提升它的agentic能力，再让它学会使用外部工具，那么不久的将来，它就能可信地自动进行科研工作。虽然这些是非常重要且激动人心的技术路线，但我们认为，即使大模型可以变得非常强大智慧，也不一定“可信”。这是因为，对于科学或者说科研，大家并没有一致认同的标准答案。一个学科里会有观点相左的不同学派，不同实验室对于科研的理解和规则也会有差异。在执行重要任务时，这些差异会体现在操作细则的各个方面，而且越是重要的任务，越缺少妥协的余地。倘若向全世界最强的智能体丢一句简单的命令，让它根据自己的想法全自动做科研，然后直接把结果端给用户，对于严肃的科研工作者来说恐怕是难以接受的。

所以我们认为，可信的科学自动化，首先要让用户选择自己信任的guidelines。这个guidelines也许只是一个具体任务的简单指示，也许是复杂得多的一组文件。对于要进行的任务来说，这个guidelines要包含足够的文本信息让用户确信自己认同它将在这个任务中体现的科研风格、学派立场等等，于是用户在充分知情与认同的前提下，对产出的结果承担信任与责任。而agent这一侧，则需要确保按照用户信任的guidelines工作，同时也要对实际执行中的各种问题自主地探索解决方案，灵活处理，避免像人为编排的工作流那样僵化。因此，一个可信的智能体是需要结合agent和workflow优势的。

当然，以上更多是原则性的思考。由于大模型的概率本质，我们无法确保智能体100%的遵守guidelines，而是通过智能体的编排，在大模型指令遵守和减少幻觉方面进展的基础上再进一步。

## 方法设计：把可控的指南与自主的智能体放到一起

围绕“可信”这一目标，我们把 GenoMAS 设计成一个多角色协作的系统，但始终坚持两个原则：一是在执行任务全过程中加强智能体对guidelines的遵循；二是让智能体在该框架内保留足够的自主，针对真实数据的边界情况进行探索、回退与修正。为此，我们把指南组织成可编辑的 DAG，并进一步切分为语义自洽、可原子执行的 Action Unit。编程类智能体在每一步都会基于上下文做出“前进/修订/跳过/回退”的选择：当早期决策导致下游异常时，可以回滚代码与状态到合适的分叉点，沿替代路径继续推进。

系统由六个角色协作完成端到端流程（如图1所示）：PI 负责统筹与调度；两位数据工程师分别面向 GEO 与 TCGA 的数据预处理；统计学家承担回归建模与显著基因识别；代码审阅者与领域专家提供质量控制与生物学判断。角色之间通过“带类型的消息协议”通信，形成清晰的请求—响应闭环，避免跨步与遗漏。在代码层面，我们采用“编写—审阅—修订”的多轮循环：审阅者在隔离上下文的前提下检查可执行性与对指南的遵守，必要时给出精确的拒绝与修改建议；编程智能体据此整合历史诊断信息进行修订，直到通过或达到上限。涉及生物学语义的决策（如特征抽取与基因符号映射），由领域专家在聚焦上下文中给出建议，并直接以可执行的形式落地。

为了应对真实数据规模与异质性，我们在工程上加入并行与断点续跑、缓存与资源监控、超时保护等机制；通过“代码记忆”，系统把已通过审阅的片段按 Action Unit 类型索引与重用，从而在保持稳健的前提下逐步积累经验，减少无谓重复。为了保证可复现性与一致性，我们将基因同义词库与基因-表型关联资源本地化、版本化管理。值得一提的是，我们选择“异质模型”的团队配置：擅长代码代理的模型承担编程主力，更强的推理模型主导规划与审阅，而在生物知识上表现突出的模型提供领域判断；这种认知多样性在复杂任务上通常更稳健。

![编程智能体的规划、记忆与自纠机制](GenoMAS_figs/Programming_agent.png)

- 图2（编程智能体机制）：单个编程智能体的规划、代码记忆与自我纠错流程示意。

## 实验与结果：在 GenoTEX 上的系统检验

我们在 GenoTEX 基准上系统评估 GenoMAS。该基准覆盖 913 个真实数据集、132 个表型、共 1,384 个基因-表型问题，按照“数据选择—数据预处理—统计分析”三段式进行度量。在数据预处理阶段，我们采用属性交并系数（AJ）、样本交并系数（SJ）与复合相似相关（CSC=AJ×SJ×相关系数均值）来衡量结构与数值的一致性；在统计分析阶段，采用 AUROC、Precision/Recall/F1 与 GSEA 等指标，额外记录端到端执行成功率、时间与成本。

在该基准上，GenoMAS 在数据预处理取得 89.13% 的 CSC，在显著基因识别上取得 60.48% 的 F1，相比此前最优方法分别提升 10.61% 与 16.85%；端到端执行成功率为 98.78%，同时将 API 成本降低了约 44.7%。在同构（单一模型）与异构（多模型协作）的对照中，异构配置带来了额外收益：在保持可控性的同时进一步提升了识别能力，并显著降低了成本。我们也观察到，强通用工具集成的生物医学智能体在这一任务上并不占优，原因并不在于“模型不够强”，而在于设计侧重点不同：本任务更需要在“遵循可复核指南”的前提下处理复杂依赖与边界情形，而不是面向开放域的完全自主。

![主要结果表（论文表1截图）](GenoMAS_figs/Main_result_table.jpg)

- 图3（主结果对比）：GenoMAS 在 GenoTEX 上的端到端性能对比（F1 提升 16.85%，AUROC 提升 0.17，API 成本降低约 44.7%）。

## 进一步分析：瓶颈、消融与系统行为

把流程拆开看，数据集筛选的难度相对较低，但早期偏差会层层放大。数据预处理呈现典型分化：在表达矩阵处理上，系统取得了稳定的高一致性；而在临床特征抽取上，受制于半结构化文本、命名异构与来源不一致，CSC 明显偏低，是当前主要瓶颈。在统计分析环节，我们用专家预处理数据做了对照：当批次效应校正与协变量控制具备时，F1 可达到约 95% 水平；去掉批次效应校正会显著下降。这一对比表明，困难不在于使用何种回归模型，而在于能否可靠地处理混淆。

在消融实验中，去掉情境感知的引导式规划、领域专家或多轮审阅，都会带来明显退化；把审阅轮数限制为 1 轮进一步说明“看似笨重”的迭代在长链路里确有必要。我们还设置了“零样本、不读数据”的对照，AUROC 仅在 0.56 左右，强调了结构化数据处理与领域推理的不可替代性。从系统行为看，代码记忆在前期很快达到约 65% 的复用率，累计节省了可观的时间；消息流量集中在规划与校验上，PI 低频调度、编程与顾问高频互动的模式与真实跨学科团队相似。

![智能体合作模式与消息分布](GenoMAS_figs/Agent_collaboration_patterns.jpg)

- 图4（合作模式示意）：智能体通信网络与消息类型分布。数据工程师（含 GEO/TCGA）承担多数交互，PI 低频调度，规划请求占比最高，体现“引导式规划 + 多轮审阅”的主轴。

小结（定性观察）：在一个代表性的 20 个问题会话中，数据工程师角色主导约过半的信息交互，统计学家负责分析阶段的关键回合；PI 仅少量消息用于编排，体现高度自治。消息类型统计显示规划请求/响应居首，其次是代码校验请求；低频的“需要修订”说明引导式规划与多轮顾问机制能提前预防错误、提高成功率（我们观测到端到端成功率约 98.78%）。这一通信结构与角色分工，强调了“集中执行 + 分布式专长”的好处：在保持可控性的同时，保留了对边界情形的适配能力。

## 收束与展望

回到最初的问题：如何让一个完全自动化的系统在真实科研任务上“值得信任”。GenoMAS 的答案并不依赖某个单一的“更大”或“更强”，而是把可复核的指南、自治的执行与严格的审阅组织在一起，并在真实数据的异质性与边界条件中持续锤炼。它不是终点：临床特征抽取的稳健性、极端数据情形的处理、对指南的进一步可验证遵循，都还有改进空间。我们也在探索把这一范式推广到更复杂的多组学与多模态场景，结合更强的规划算法与更细粒度的执行追踪，加强对因果与混淆的刻画。

如果这篇报道有意义，可能在于它展示了一条务实的路径：先把“如何做事”说清楚，再让系统在这个框架内独立工作、犯错与修正，并用数据说话。我们希望继续把这条路径走实，欢迎同行审视与讨论。
