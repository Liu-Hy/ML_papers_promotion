标题：把“弯曲”抹平：我们如何用几分之一的数据，炼出既准确又抗攻击的模型

在数据越来越多、模型越练越大的今天，“数据蒸馏”让我们看到一条优雅但务实的路：把海量训练集压缩成每类仅几张的“精华集”，再用它们训练出精度不输全量数据的模型。然而，效率之外，可信赖性同样关键——当模型面对对抗攻击时，训练在蒸馏数据上的模型还能扛得住吗？我们在 AAAI 2025 的新作提出：不仅要“压缩”数据，更要把“鲁棒性”一起压进去。为此，我们给出一种简单高效、带有理论支撑的做法：通过“曲率正则”在蒸馏过程中直接塑造可迁移的对抗鲁棒性。我们将其命名为 GUARD（Geometric Regularization for Adversarially Robust Dataset）。

直觉上，最自然的办法是把对抗训练嵌入蒸馏流程：用鲁棒模型作“教师”，以此提炼更抗攻击的合成样本。但实践却给出了相反信号。我们在 SRe2L 框架上做了一个小心翼翼的例子：只用非常弱的 PGD（ϵ=1/255）参与蒸馏阶段的对抗训练，得到的蒸馏数据在干净测试上的性能却显著崩塌，例如 ImageNette 10 IPC 的干净准确率从 42.42% 跌到 12.81%，鲁棒性也并不稳定。这并不意外——已有研究指出对抗训练会改变图像的语义表征，蒸馏又极度压缩了分布，两者叠加反而容易把“精华”扭曲掉。这促使我们转向更本质的提法：不是在外层堆叠一个对抗环路，而是从损失几何出发，直接改造模型面对真实数据时的“局部曲率”。

核心理论结论非常朴素却有力：把样本在小球扰动内的对抗损失近似展开，可以得到一个上界，其中最重要的项来自损失对输入的“最大曲率”（Hessian 最大特征值）。在假设蒸馏数据已能较好贴近真实分布（特征距离 σ 足够小）、且最优点附近梯度项影响相对次要的情况下，这个上界的主导因子就是曲率本身。换句话说，只要我们让模型在真实数据邻域的损失面更“平”，训练在蒸馏数据上的模型就能继承到更强的对抗鲁棒性。这一视角的一个重要副产物是可迁移性保证：真实数据与蒸馏数据上的对抗损失上界只相差一个与 σ 成正比的常数项，因此“在蒸馏数据上优化鲁棒性”能够可靠地转移到“在真实数据上评测鲁棒性”。

基于此，我们提出 GUARD 曲率正则。直接算 Hessian 最大特征值代价太高，我们借助经验事实：梯度方向与最大曲率方向在输入空间往往高度相似。于是我们用单位梯度方向做一个小步长扰动，最小化两处梯度的差异范数，让损失面在这一方向上尽量线性化。这等价于最小化曲率的高效近似。落地实现上，我们把这项正则嵌入 SRe2L 的 squeeze 阶段，将其标准训练损失替换为“原损失 + 曲率正则”，每个迭代仅多一次前向与梯度计算即可，无需引入内层对抗环路。测得的代价非常低：在 A100 80GB 上每步仅约 0.007s，峰值显存约 3.8GB，对比把对抗训练硬塞进蒸馏要 2.198s/步与更高的显存占用。工程上，GUARD 更像一个“即插即用”的小组件，而不是一个重工程的三层优化器。

实验方面，我们在 ImageNette、Tiny ImageNet 和 ImageNet-1K 上系统评估，统一用 ResNet-18 进行蒸馏与验证，并覆盖 PGD100、Square、AutoAttack、CW、MIM 等多种白盒/黑盒攻击。在多个蒸馏规模（10/50/100 images per class）下，GUARD 在鲁棒指标上广泛优于强基线，并常常“顺带”提升干净精度。例如，在 ImageNette 10 IPC 上，GUARD 的干净准确率为 57.93%，对比原 SRe2L 的 42.42%；在同设下，PGD100 从 4.76% 提升到 23.87%，AutoAttack 从 4.99% 提升到 19.69%。Tiny ImageNet 的 50 IPC 场景中，PGD100 从 0.27% 显著提升到 15.63%，AutoAttack 从 0.16% 提升到 13.84%。在更具挑战的 ImageNet-1K 10 IPC 上，干净准确率由 21.30% 提升到 27.25%，PGD100 从 0.55% 提升到 5.25%。当压缩比例放宽到 ImageNette 100 IPC，PGD100 由 31.65% 提升到 57.50%，AutoAttack 由 17.93% 提升到 64.84%。这些结果揭示了一个耐人寻味的规律：通过让损失几何更“平”，我们不仅把鲁棒性“蒸”了进去，还让模型对干净样本的泛化更稳了。这与正则化帮助泛化的一般认识相呼应。

我们也认真做了对比与消融。首先，把“梯度范数”本身当作正则（而不是曲率差分）并不能带来同等的鲁棒提升，说明“针对曲率”的几何塑形是关键。其次，直接在蒸馏里做对抗训练的替代方案不仅算力高、内环复杂，还容易出现我们前面提到的语义扭曲与分布错配，实验数据清楚地显示它对干净精度造成了灾难性打击且鲁棒收益并不稳定。最后，我们验证了 GUARD 的可迁移性与普适性：把它加到 DC 与 CDA 这样的不同蒸馏范式上，在 CIFAR-10 的 1 / 10 / 50 IPC 各种设定下，GUARD 也能同时提升干净与鲁棒性能。这支持了我们的设计初衷——GUARD 是一个可以贴合多种蒸馏框架的轻量几何正则，而不是某一特定算法的“私有优化”。

从机制直觉看，为什么“把曲率压平”能帮助蒸馏鲁棒性？我们可以把它理解为一种“几何上的容量匹配”。蒸馏场景下，学生模型最终只会在一个极其稀疏的合成数据支撑集上学习；如果教师模型在真实数据邻域的损失曲面崎岖、曲率大，那么它在这些邻域里的最陡上升方向会频繁改变，导致从教师可恢复、可对齐的统计变得不稳定。相反，当我们在教师训练阶段显式压低损失的最大曲率，使其在梯度主导方向上更接近局部线性，蒸馏算法便能从教师身上“读”到更加一致的几何信号：梯度在小球内不剧烈摆动，内在对抗方向不容易形成锋利的“上坡”，恢复/对齐出来的合成样本更稳定地贴近类条件流形。这种稳定性一方面直接抑制了对抗扰动在小邻域内的增幅，另一方面也让学生在小样本训练时更不容易被偶然的高曲率尖峰牵着走，从而同时提升鲁棒性与干净泛化。

这种几何容量匹配还解释了一个看似“意外”的现象：在更小的 IPC（例如 1 或 10）下，曲率正则往往还能带来显著的干净准确率提升；而当 IPC 较大时，若正则过强则可能抑制必要的细粒度判别，此时适当减弱正则强度（例如调小 λ 或步长 h）便能在保持鲁棒收益的同时避免精度回落。本质上，IPC 越小，能承载的模型复杂度就应越低——通过压平曲率，我们把教师/学生的有效容量“调低”，令其归纳偏置与稀疏的蒸馏数据相匹配；IPC 增大时，再逐步放开这一约束。

值得区分的是，“几何正则”与“强数据增强”在蒸馏中扮演的角色并不相同。过度的增强会向教师引入与目标任务不完全一致的不变性偏置，进而把本就紧凑的合成分布推离真实决策边界；而曲率正则不改写输入分布本身，它只是平整损失几何，使教师的表征与梯度在局部上更稳定、更可迁移。这也解释了为什么在不少设置中，我们一边压平曲率，一边看到由蒸馏得到的模型在干净集和对抗集上同时受益。

最后，理论上我们给出的上界也与上述直觉相吻合：对抗损失在真实数据与蒸馏数据之间仅相差一个与特征偏差 σ 成比例的常数项；当蒸馏对齐做得足够好时，主要的可控因子就是最大曲率。于是，“在蒸馏数据上平整损失面”可以有效迁移为“在真实数据上更难被攻击”，而不必引入昂贵的内环对抗训练。

当然，我们并不宣称这是一种形式化可证的全局鲁棒保证。理论推导采用了合理但理想化的假设（如局部凸性、特征映射的 Lipschitz 等），因此它提供的是“方向性的指导与上界控制”，而非逐点的最优证书。但正如大量实证所示，这一几何约束在实际深度网络的局部区域是行之有效的：它既避免了对抗训练那样的三层优化开销，也在大规模数据与强攻击设置下给出了兼顾精度与鲁棒的均衡解。

我们相信，GUARD 提供的是一种“把鲁棒性也蒸馏出来”的新范式。面向算力受限的边端与隐私敏感的场景，它可以显著降低训练成本；面向大模型与大数据，它以极低的增量开销，把“强健的损失几何”注入训练流程；面向方法学发展，它以清晰的几何解释连接了蒸馏、鲁棒与泛化这三者。论文与代码已开源，欢迎检阅与复现：https://github.com/yumozi/GUARD。我们也期待社区把这类曲率正则进一步推广到更多蒸馏家族甚至分布外鲁棒场景，让“小而强”的数据集成为通往可信 AI 的一条可持续道路。