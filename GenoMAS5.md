# 科学自动化的信任难题：从基因分析看智能体如何学会"靠谱"

- 论文标题：GenoMAS: A Multi-Agent Framework for Scientific Discovery via Code-Driven Gene Expression Analysis
- arXiv 链接：https://arxiv.org/abs/2507.21035

## 自动化的尽头是信任

在实验室里，当一个博士生把自己辛苦收集的数据交给另一个同学分析时，他会担心什么？也许是担心对方不够细心，会在某个关键步骤出错；也许是担心对方的分析思路和自己的研究假设不一致。但无论如何，他可以和对方反复沟通，确认每一步的处理方式，最终对结果负责。

现在，如果要把同样的任务交给一个智能体系统呢？问题立刻变得微妙起来。当代大模型的能力已经令人惊叹，它们能够理解复杂指令、编写代码、调用工具。但"能够完成"和"值得信任"之间，存在着本质的差距。尤其是在科学研究这样对准确性和可重复性有着严苛要求的领域，任何自动化系统都必须回答一个根本问题：凭什么让研究者相信你的分析是可靠的？

我们在过去一年半的工作，就是试图在基因表达分析这个场景下，为这个问题提供一个具体的答案。这个任务本身就充满挑战：需要处理来自GEO和TCGA等数据库的原始转录组数据，应对不同测序平台的异质性，理解半结构化的临床信息，控制批次效应和各类混淆因素，最终识别出与目标表型真正相关的基因集合。整个流程涉及数据选择、预处理、统计建模三个主要阶段，每个阶段都需要领域知识和编程能力的深度结合。如果智能体能够在这样的任务上做到可信，那它才算得上是真正走进了科学研究的内核。

![GenoMAS 多智能体系统示意图](GenoMAS_figs/System_diagram.png)

- 图1：GenoMAS通过六个专业角色的协作，实现从原始数据到基因识别的端到端自动化分析。

## 当最强智能体遇到真实科研任务

在着手设计系统之前，我们做了大量的前期调研和测试。这个过程让我们对问题的难度有了切身体会。

首先是建立评估基准的困难。我们需要一套由领域专家完成的高质量分析作为参照，才能评判自动化方法的好坏。但当我们向一位CMU的计算生物学教授提议，把这个任务作为研究生课程项目时，她看了流程后直言："太专业了，这对学生是过大的挑战。"最终我们只能自己组织团队，花费大量时间学习相关知识、编写代码，才逐步构建出GenoTEX这个包含913个数据集、132个表型、1,384个分析问题的基准。这个过程本身就说明，即使对受过良好训练的研究者来说，这也是一个需要长期学习和实践才能掌握的专业技能。

然后是测试现有智能体的失望。在GPT-4时代，几乎没有方法能够生成可执行的完整分析代码。即使到了Claude Sonnet 3.5这样的强模型出现后，代码执行不再是问题，但我们发现了更深层的困难：智能体会犯那种"看起来合理但实际致命"的错误。比如在处理门静脉高压的研究中，把肝硬化样本错误地归类为对照组——因为模型没有理解肝硬化正是导致门静脉高压的主要病因之一。再比如在需要批次效应校正的场合直接跳过，因为模型觉得"数据看起来还可以"。这些错误在代码层面没有任何报错，但会让整个科学分析失去意义。

这些观察让我们意识到，问题的核心不在于模型是否"足够强"，而在于缺少某种机制来确保分析过程的科学严谨性。大模型的能力来自于对互联网海量文本的统计学习，当任务足够专业化、足够依赖领域判断时，纯粹的统计泛化就会露出破绽。更重要的是，大模型处理信息的方式——把一切都转化为字符串序列——与人类专家的工作方式有着本质差异。一个熟练的生物信息学家在分析时，会有目的地打开某个数据文件，定位到关键的几行或几列，根据这些信息做出判断，然后决定下一步操作。这种主动的、有选择的信息处理方式，是当前智能体架构难以复制的。

## 在指南与自主之间找到平衡点

那么，可信的科学自动化应该是什么样子？我们的答案可能会让一些人感到意外：它不应该是一个完全自主的黑盒，而应该是一个能够严格遵循用户指定的分析规范、同时又具备自主解决问题能力的系统。

这个想法来自对科研实践的观察。在真实的研究工作中，不同的实验室、不同的学派，对于"正确的分析方式"往往有着自己的理解和偏好。这些差异不是谁对谁错的问题，而是研究哲学和方法论选择的体现。一个严肃的研究者不会盲目接受一个系统生成的结果，除非他清楚地知道这个系统遵循的是什么样的分析逻辑和质量标准。换句话说，可信不仅仅意味着"做得对"，更意味着"做得明白"——用户需要能够审视和认同系统的工作方式。

基于这个认识，GenoMAS采用了一个双层设计。第一层是用户提供的分析指南，它以有向无环图的形式组织，明确规定了分析的主要步骤、依赖关系和质量要求。这个指南可以是简单的，也可以是详尽的，关键是它反映了用户对"如何正确做这件事"的理解。第二层是智能体的自主执行，它不是机械地按照指南逐步操作，而是能够根据实际遇到的数据情况，灵活地规划、调整、甚至回退。这两层的结合，既保证了分析过程的可控性和可审计性，又保留了应对复杂现实的适应能力。

具体实现上，我们把指南分解为一个个Action Unit——每个单元代表一个语义完整、可独立执行的操作，比如"加载数据"、"提取临床特征"、"基因符号映射"、"批次效应校正"等。编程智能体在每个节点上，都会根据当前的任务上下文做出决策：是继续前进到下一个预期的单元，还是因为遇到问题需要修订当前代码，或者发现之前的某个决策导致了下游困难而需要回退重来。这种引导式规划机制，让系统既有章可循，又不会因为预设的路径无法覆盖所有边界情况而失败。

## 让智能体像团队一样协作

如果说引导式规划解决了"做什么"和"怎么做"的问题，那么多智能体协作就是为了解决"谁来做"和"如何做对"的问题。

GenoMAS不是一个单一的智能体，而是一个由六个专业角色组成的团队。PI担任总协调人，两个数据工程师分别负责GEO和TCGA数据的预处理（因为两个平台的数据格式和处理流程差异很大），统计学家负责回归分析和基因识别，代码审阅者负责质量把关，领域专家在需要生物学判断的节点提供指导。这些角色通过结构化的消息传递协议进行交互，每条消息都有明确的发送方、接收方、类型和内容，形成了一个有序的协作网络。

![编程智能体的规划、记忆与自纠机制](GenoMAS_figs/Programming_agent.png)

- 图2：单个编程智能体的内部机制——它如何规划、如何记忆、如何在多轮交互中纠错。

这个设计的一个关键特点是角色之间的制衡。编程智能体写完一段代码后，不是立即执行，而是发送给审阅者。审阅者在一个隔离的上下文中——只看到代码本身、整体任务描述和这一步的具体要求，但看不到之前的试错历史——独立地评估这段代码是否正确、是否符合指南要求。如果发现问题，审阅者会给出具体的修改建议；编程智能体收到反馈后，结合自己的完整历史信息，重新生成代码。这个过程可以迭代多轮，直到审阅通过。

对于那些需要生物学知识做判断的步骤，比如从复杂的临床描述文本中提取标准化的表型变量，或者处理基因命名的历史演化和同义词问题，系统会咨询领域专家。领域专家接收到的是经过提炼的、聚焦于生物学内容的信息，而不是完整的代码和技术细节。它给出的建议也直接以可执行代码的形式返回，这样就把领域知识无缝地嵌入到了编程流程中。

我们在实现时做了一个有意思的选择：不同角色使用不同的大模型作为后端。编程智能体使用擅长代码生成的Claude Sonnet 4，审阅者和规划逻辑使用推理能力更强的OpenAI o3，领域专家使用在生物医学知识上表现优异的Gemini 2.5 Pro。这种异构配置来自组织科学中"认知多样性"的理念——一个由不同专长的人组成的团队，往往比一群同质化的专家更能应对复杂问题。我们的实验确实验证了这一点：异构配置相比于全部使用同一个模型，在准确性和成本效率上都有显著优势。

此外，系统还维护了一个"代码记忆"。每当一段代码通过审阅，它就会被存储到按Action Unit类型索引的记忆库中。后续遇到类似任务时，系统可以直接复用或改编这些已验证的代码片段，既提高效率，又积累经验。我们观察到，随着处理的数据集增多，代码复用率能稳定在65%左右，为整体流程节省了大量时间。

## 在真实数据上经受考验

GenoTEX基准为评估提供了一个接近真实科研的测试环境。它不仅覆盖了从原始数据到分析结果的完整流程，而且涉及的都是真实的基因组数据和临床表型，包含了平台差异、批次效应、缺失值、命名不一致等各种"真实世界的混乱"。评估也是多维度的：数据预处理阶段看结构和数值的一致性，统计分析阶段看基因识别的准确性，同时还记录执行成功率、时间成本和API开销。

![主要结果表](GenoMAS_figs/Main_result_table.jpg)

- 图3：GenoMAS在各项指标上相对于现有方法的提升。

结果证明了我们的设计思路。GenoMAS在数据预处理上达到89.13%的复合相似相关度，在基因识别上达到60.48%的F1分数，相比此前最好的方法GenoAgent分别提升了10.61和16.85个百分点。更重要的是，端到端成功率达到98.78%，这意味着系统在绝大多数情况下都能稳定地完成从数据到结果的全流程，而不会在某个环节崩溃。同时，由于异构配置和代码复用的效率优化，API成本降低了约44.7%。

我们也测试了一些现有的优秀智能体系统。Biomni是一个专门为生物医学设计的通用智能体，集成了150多个工具和大量数据库，在很多任务上表现出色。但在我们的基准上，它的F1只有14.82%。这并不是说Biomni不够好，而是说明了任务性质的差异：我们的任务强调的不是"在开放环境中自主探索解决方案"，而是"在给定规范下严格可靠地执行复杂流程"。后者需要的是精确的过程控制和系统性的错误预防，而不仅仅是工具的丰富性和模型的通用性。

把性能拆解到各个阶段看，能更清楚地看到瓶颈所在。在数据集选择上，智能体的表现相对较好，说明基于元数据的判断对现有模型来说不算太难。在基因表达矩阵的预处理上，系统达到了91.15%的一致性，表明对数值数据的处理已经很稳健。但在临床特征提取上，一致性只有32.61%，这是当前最大的短板。原因在于临床信息往往以半结构化甚至自由文本的形式存在，同一个概念在不同数据集中可能有完全不同的表述，而且有时需要从间接信息中推断。这对领域知识的深度和语义理解的精细度都提出了很高要求。

![智能体合作模式与消息分布](GenoMAS_figs/Agent_collaboration_patterns.jpg)

- 图4：从实际运行中的消息流量，可以看出各角色的分工和交互模式。

我们还做了一个有趣的对照实验：如果直接使用人类专家预处理好的数据，让系统只做统计分析，它的F1能达到95%以上。这说明在统计建模这个相对标准化的环节，智能体已经接近人类专家水平。问题的核心在于前面的数据处理，尤其是那些需要深度领域判断的部分。这也指明了未来改进的方向：不是简单地更换更强的模型，而是要更好地将领域知识和判断嵌入到智能体的决策过程中。

## 从消息流看系统的运行逻辑

在一个包含20个分析任务的典型会话中，我们统计了各角色之间的消息交换。数据工程师（合并GEO和TCGA）发送和接收了超过一半的消息，这符合预期，因为数据预处理是工作量最大的阶段。统计学家参与了大约11.6%的交互，主要集中在后期的分析阶段。值得注意的是，PI只占了2.3%的消息量，这说明系统有着很高的自治程度——绝大部分决策和协调都是由编程智能体和顾问智能体直接完成的，不需要中央节点频繁介入。

从消息类型看，规划请求和响应占据了最大比例，这验证了引导式规划在系统中的核心地位——几乎每一步执行前都会经过一次规划决策。代码审阅请求排在第二位，但"需要修订"的消息数量相对较少。这个现象背后的原因是，多轮审阅和引导式规划起到了前置预防的作用：很多潜在问题在代码真正执行前就被发现和修正了，所以最终提交审阅的代码通过率较高。这也解释了为什么系统能达到98.78%的端到端成功率——不是因为不出错，而是因为能够及早发现错误、及时纠正。

消融实验系统地验证了各个组件的价值。去掉引导式规划，系统只能按照固定的DAG流程执行，性能明显下降，说明动态规划和回退机制对于应对真实数据的多样性至关重要。去掉领域专家，编程智能体和代码审阅者虽然也能工作，但在需要生物学判断的地方会犯错，导致整体准确性下降。把审阅轮数限制为一轮，性能也会降低，说明多轮迭代不是冗余，而是达到高质量代码的必要过程。

## 展望：从基因分析到更广阔的科学自动化

GenoMAS的工作聚焦于一个具体的科学任务，但我们相信它提出的一些设计原则具有更广泛的适用性。可信的科学自动化需要在三个层面找到平衡：在控制与自主之间，通过用户指定的指南和智能体的动态执行相结合；在通用与专业之间，通过异构团队和领域专家嵌入来补充模型的知识短板；在效率与稳健之间，通过代码记忆和多轮审阅来积累经验同时保证质量。

当然，这个工作还远未完成。临床特征提取的瓶颈需要更深入的语义理解和知识整合。对于极端情况和异常数据的处理还需要更多的机制保障。指南的形式化程度和可验证性也有提升空间。我们正在将这套方法扩展到多组学数据整合、因果推断等更复杂的场景，也在探索如何通过更强的规划算法和更细粒度的执行跟踪，让系统的决策过程更加透明可解释。

但至少在基因表达分析这个任务上，我们证明了：智能体可以通过适当的架构设计，在保持自主性和适应性的同时，达到科研工作所需要的可信度。这是智能体技术从"能用"走向"可靠"的重要一步。随着大模型能力的持续提升和更多领域最佳实践的积累，我们有理由期待，在不太遥远的将来，这样的可信智能体能够成为科研人员真正的得力助手，让研究者把更多精力放在创造性的思考上，而把繁重的数据处理和标准化分析交给值得信赖的自动化系统。这才是智能体技术应该追求的目标。
